{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "codeA = pd.read_csv('data/Train/tc_codea_코드A.csv')\n",
    "codeB = pd.read_csv('data/Train/tc_codeb_코드B.csv')\n",
    "code_area = pd.read_csv('data/Train/tc_sgg_시군구코드.csv')\n",
    "\n",
    "# 라벨링 데이터\n",
    "\n",
    "# 그 뭘 했었는지 - 방문장소 , 여기서 방문한 장소의 타입을 찾을 수 있음\n",
    "visit_area_info = pd.read_csv('data/Train/tn_visit_area_info_방문지정보_merged.csv')\n",
    "traveler_master = pd.read_csv('data/Train/tn_traveller_master_여행객 Master_merged.csv')\n",
    "\n",
    "# 돈은 얼마나 쓰는지 - 지출내역\n",
    "adv_consume_his_act = pd.read_csv('data/Train/tn_activity_consume_his_활동소비내역_t.csv')\n",
    "\n",
    "# 뭘 타고는지 - 이동수단소비내역\n",
    "move_consume_his = pd.read_csv('data/Train/tn_mvmn_consume_his_이동수단소비내역_merged.csv')\n",
    "\n",
    "companion_info = pd.read_csv('data/Train/tn_companioninfo동반자정보_t.csv')\n",
    "\n",
    "# 여행 목적 - 여행 페르소나\n",
    "travel = pd.read_csv('./data/Train/tn_travel_여행_merged.csv')\n",
    "\n",
    "# TODO: 감정 (무드)를 추출해보기 위한 데이터 추후 추가 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 크기: 36646\n"
     ]
    }
   ],
   "source": [
    "valid_area_type_codes = list(range(1, 9))\n",
    "visit_area_info = visit_area_info[ (visit_area_info['VISIT_AREA_TYPE_CD'].isin(valid_area_type_codes))]\n",
    "print(f\"데이터 크기: {len(visit_area_info)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "visit_area_info = visit_area_info.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 6, 4, 3, 7, 5, 8])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visit_area_info['VISIT_AREA_TYPE_CD'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "visit_area_info.dropna(subset = ['LOTNO_ADDR'], inplace = True)\n",
    "visit_area_info = visit_area_info.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sido = []\n",
    "gungu = []\n",
    "for i in range(len(visit_area_info['LOTNO_ADDR'])):\n",
    "    sido.append(visit_area_info['LOTNO_ADDR'][i].split(' ')[0])\n",
    "    gungu.append(visit_area_info['LOTNO_ADDR'][i].split(' ')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "visit_area_info['SIDO'] = sido\n",
    "visit_area_info['GUNGU'] = gungu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SIDO\n",
       "제주특별자치도    8578\n",
       "경기         3506\n",
       "서울         2507\n",
       "경북         2432\n",
       "전남         2286\n",
       "전북         1947\n",
       "충남         1914\n",
       "강원특별자치도    1870\n",
       "부산         1758\n",
       "경남         1459\n",
       "강원         1308\n",
       "충북         1213\n",
       "인천         1205\n",
       "대전         1171\n",
       "대구          455\n",
       "광주          322\n",
       "울산          293\n",
       "세종특별자치시     223\n",
       "강원도           5\n",
       "부산광역시         4\n",
       "경상북도          4\n",
       "전라남도          3\n",
       "충청남도          3\n",
       "경기도           3\n",
       "전라북도          3\n",
       "충청북도          2\n",
       "경상남도          1\n",
       "대전광역시         1\n",
       "서울특별시         1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visit_area_info['SIDO'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "visit_area_info = visit_area_info[['TRAVEL_ID', 'VISIT_AREA_NM', 'SIDO', 'GUNGU', 'VISIT_AREA_TYPE_CD', 'DGSTFN',\n",
    "                                'REVISIT_INTENTION', 'RCMDTN_INTENTION', 'RESIDENCE_TIME_MIN', 'REVISIT_YN']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAVEL_MISSION_CHECK의 첫번째 항목 가져오기\n",
    "travel_list = []\n",
    "for i in range(len(travel)):\n",
    "    value = int(travel['TRAVEL_MISSION_CHECK'][i].split(';')[0])\n",
    "    travel_list.append(value)\n",
    "\n",
    "travel['TRAVEL_MISSION_PRIORITY'] = travel_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "travel = travel[['TRAVEL_ID', 'TRAVELER_ID', 'TRAVEL_MISSION_PRIORITY']]\n",
    "travel.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "traveler_master = traveler_master[['TRAVELER_ID', 'GENDER', 'AGE_GRP', 'INCOME', 'TRAVEL_STYL_1', \n",
    "                                     'TRAVEL_STYL_2', 'TRAVEL_STYL_3', 'TRAVEL_STYL_4', 'TRAVEL_STYL_5', \n",
    "                                     'TRAVEL_STYL_6', 'TRAVEL_STYL_7','TRAVEL_STYL_8', \n",
    "                                      'TRAVEL_MOTIVE_1', 'TRAVEL_NUM', 'TRAVEL_COMPANIONS_NUM' ]]\n",
    "traveler_master.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "결측치 제거 전 데이터 크기: 70874\n"
     ]
    }
   ],
   "source": [
    "valid_codes = list(range(1, 8))  # 1부터 7까지의 리스트\n",
    "adv_consume_his_act = adv_consume_his_act[\n",
    "    (adv_consume_his_act['ACTIVITY_TYPE_CD'].isin(valid_codes))\n",
    "]\n",
    "print(f\"결측치 제거 전 데이터 크기: {len(adv_consume_his_act)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "결측치 제거 후 데이터 크기: 70627\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 결측치 제거\n",
    "adv_consume_his_act = adv_consume_his_act.dropna(subset=['STORE_NM'])\n",
    "adv_consume_his_act = adv_consume_his_act[['TRAVEL_ID', 'ACTIVITY_TYPE_CD', 'STORE_NM']]\n",
    "\n",
    "print(f\"결측치 제거 후 데이터 크기: {len(adv_consume_his_act)}\")\n",
    "adv_consume_his_act.to_csv('svd_travel_cosume_act_results.csv', index=False)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 동반자 정보\n",
    "  - 1182,TCR,\"1\",배우자,\"\",\"\",N,999,\"2022-09-22 17:34:50\",\n",
    "  - 1183,TCR,\"2\",자녀,\"\",\"\",N,999,\"2022-09-22 17:34:50\",\n",
    "  - 1184,TCR,\"3\",부모,\"\",\"\",N,999,\"2022-09-22 17:34:50\",\n",
    "  - 1185,TCR,\"4\",조부모,\"\",\"\",N,999,\"2022-09-22 17:34:50\",\n",
    "  - 1186,TCR,\"5\",형제/자매,\"\",\"\",N,999,\"2022-09-22 17:34:50\",\n",
    "  - 1187,TCR,\"6\",친인척,\"\",\"\",N,999,\"2022-09-22 17:34:50\",\n",
    "  - 1188,TCR,\"7\",친구,\"\",\"\",N,999,\"2022-09-22 17:34:50\",\n",
    "  - 1189,TCR,\"8\",연인,\"\",\"\",N,999,\"2022-09-22 17:34:50\",\n",
    "  - 1190,TCR,\"9\",동료,\"\",\"\",N,999,\"2022-09-22 17:34:50\",\n",
    "  - 1191,TCR,\"10\",\"친목 단체/모임(동호회, 종교단체 등)\",\"\",\"\",N,999,\"2022-09-22 17:34:50\",\n",
    "  - 1192,TCR,\"11\",기타,\"\",\"\",N,999,\"2022-09-22 17:34:50\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_companion_codes = list(range(1, 11)) # 1부터 10까지의 리스트\n",
    "companion_info = companion_info[(companion_info['REL_CD'].isin(valid_companion_codes))]\n",
    "\n",
    "companion_info = companion_info[['TRAVEL_ID', 'REL_CD']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_consume_his = move_consume_his[['TRAVEL_ID', 'MVMN_SE_NM']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(travel, traveler_master, left_on = 'TRAVELER_ID', right_on = 'TRAVELER_ID', how = 'inner')\n",
    "df.to_csv('svd_travel_0_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(visit_area_info, df, left_on = 'TRAVEL_ID', right_on = 'TRAVEL_ID', how = 'right')\n",
    "df.to_csv('svd_travel_1_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(companion_info, df, left_on = 'TRAVEL_ID', right_on = 'TRAVEL_ID', how = 'right')\n",
    "df.to_csv('svd_travel_2_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(adv_consume_his_act, df, left_on = 'TRAVEL_ID', right_on = 'TRAVEL_ID', how = 'right')\n",
    "df.to_csv('svd_travel_3_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(move_consume_his, df, left_on = 'TRAVEL_ID', right_on = 'TRAVEL_ID', how = 'right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['RESIDENCE_TIME_MIN'] = df['RESIDENCE_TIME_MIN'].replace(0,60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['REVISIT_YN'] = df['REVISIT_YN'].replace(\"N\",0)\n",
    "df['REVISIT_YN'] = df['REVISIT_YN'].replace(\"Y\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset = ['TRAVEL_STYL_1'], inplace = True)\n",
    "df.reset_index(drop= True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset = ['TRAVEL_MOTIVE_1'], inplace = True)\n",
    "df.reset_index(drop= True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1928617, 30)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         TRAVEL_ID        MVMN_SE_NM  ACTIVITY_TYPE_CD            STORE_NM  \\\n",
      "0        e_e000004               NaN               NaN                 NaN   \n",
      "1        e_e000004               NaN               NaN                 NaN   \n",
      "2        e_e000004               NaN               NaN                 NaN   \n",
      "3        e_e000004               NaN               NaN                 NaN   \n",
      "4        e_e000004               NaN               NaN                 NaN   \n",
      "...            ...               ...               ...                 ...   \n",
      "1928612  h_h006874  자가용(승용/승합/트럭 등등)               1.0          민경이네어등포해녀촌   \n",
      "1928613  h_h006874  자가용(승용/승합/트럭 등등)               2.0  마이피기팬트리(하도리1091펜션)   \n",
      "1928614  h_h006874  자가용(승용/승합/트럭 등등)               1.0                꼬스뗀뇨   \n",
      "1928615  h_h006874  자가용(승용/승합/트럭 등등)               1.0          민경이네어등포해녀촌   \n",
      "1928616  h_h006874  자가용(승용/승합/트럭 등등)               2.0  마이피기팬트리(하도리1091펜션)   \n",
      "\n",
      "         REL_CD        VISIT_AREA_NM     SIDO GUNGU  VISIT_AREA_TYPE_CD  \\\n",
      "0           2.0  화성 관광열차 안내소 연무대 매표소       경기   수원시                 2.0   \n",
      "1           1.0  화성 관광열차 안내소 연무대 매표소       경기   수원시                 2.0   \n",
      "2           2.0                  창룡문       경기   수원시                 2.0   \n",
      "3           1.0                  창룡문       경기   수원시                 2.0   \n",
      "4           2.0            수원 화성 화홍문       경기   수원시                 2.0   \n",
      "...         ...                  ...      ...   ...                 ...   \n",
      "1928612     NaN                 꼬스뗀뇨  제주특별자치도   제주시                 3.0   \n",
      "1928613     NaN                 꼬스뗀뇨  제주특별자치도   제주시                 3.0   \n",
      "1928614     NaN             월정리 해수욕장  제주특별자치도   제주시                 1.0   \n",
      "1928615     NaN             월정리 해수욕장  제주특별자치도   제주시                 1.0   \n",
      "1928616     NaN             월정리 해수욕장  제주특별자치도   제주시                 1.0   \n",
      "\n",
      "         DGSTFN  ...  TRAVEL_STYL_2  TRAVEL_STYL_3  TRAVEL_STYL_4  \\\n",
      "0           4.0  ...              3              5              4   \n",
      "1           4.0  ...              3              5              4   \n",
      "2           4.0  ...              3              5              4   \n",
      "3           4.0  ...              3              5              4   \n",
      "4           4.0  ...              3              5              4   \n",
      "...         ...  ...            ...            ...            ...   \n",
      "1928612     3.0  ...              1              2              3   \n",
      "1928613     3.0  ...              1              2              3   \n",
      "1928614     4.0  ...              1              2              3   \n",
      "1928615     4.0  ...              1              2              3   \n",
      "1928616     4.0  ...              1              2              3   \n",
      "\n",
      "         TRAVEL_STYL_5 TRAVEL_STYL_6  TRAVEL_STYL_7 TRAVEL_STYL_8  \\\n",
      "0                    5             4              2             5   \n",
      "1                    5             4              2             5   \n",
      "2                    5             4              2             5   \n",
      "3                    5             4              2             5   \n",
      "4                    5             4              2             5   \n",
      "...                ...           ...            ...           ...   \n",
      "1928612              6             2              6             6   \n",
      "1928613              6             2              6             6   \n",
      "1928614              6             2              6             6   \n",
      "1928615              6             2              6             6   \n",
      "1928616              6             2              6             6   \n",
      "\n",
      "         TRAVEL_MOTIVE_1  TRAVEL_NUM  TRAVEL_COMPANIONS_NUM  \n",
      "0                      1           1                      2  \n",
      "1                      1           1                      2  \n",
      "2                      1           1                      2  \n",
      "3                      1           1                      2  \n",
      "4                      1           1                      2  \n",
      "...                  ...         ...                    ...  \n",
      "1928612                7           1                      0  \n",
      "1928613                7           1                      0  \n",
      "1928614                7           1                      0  \n",
      "1928615                7           1                      0  \n",
      "1928616                7           1                      0  \n",
      "\n",
      "[1928617 rows x 30 columns]\n",
      "중복 행 개수: 997108\n",
      "중복 제거 후 데이터 크기: (931509, 30)\n"
     ]
    }
   ],
   "source": [
    "print(df)\n",
    "# df.to_csv('svd_results.csv', index=False)\n",
    "print(f\"중복 행 개수: {df.duplicated().sum()}\")\n",
    "df = df.drop_duplicates()\n",
    "print(f\"중복 제거 후 데이터 크기: {df.shape}\")\n",
    "# df.to_csv('svd_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('svd_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "결측치 비율: 0.65%\n"
     ]
    }
   ],
   "source": [
    "df.isna().sum().sum()\n",
    "missing_percentage = (df.isna().sum().sum() / (df.shape[0] * df.shape[1])) * 100\n",
    "print(f\"결측치 비율: {missing_percentage:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "df_original = df.copy()\n",
    "df1 = df_original.copy()\n",
    "Train = pd.DataFrame(columns=list(df_original.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 2. Train-Test Split 수행\n",
    "\n",
    "# %%\n",
    "# 2.1 초기 데이터프레임 설정\n",
    "df1 = df_original.copy()\n",
    "Train = pd.DataFrame(columns=list(df_original.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 관광지 수: 11468개\n",
      "관광지별 사용자 데이터 준비 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "관광지 맵핑:   0%|          | 29/11468 [00:00<05:09, 37.01it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m place_to_users \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m place \u001b[38;5;129;01min\u001b[39;00m tqdm(df_original[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVISIT_AREA_NM\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique(), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m관광지 맵핑\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 19\u001b[0m     place_to_users[place] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(df_original[\u001b[43mdf_original\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mVISIT_AREA_NM\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mplace\u001b[49m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTRAVEL_ID\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# 각 관광지마다 최소 1명의 유저를 Train set에 추가 (상세 진행도 추가)\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m각 관광지별 대표 사용자 추가 중...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/travel_rec/lib/python3.8/site-packages/pandas/core/ops/common.py:81\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     79\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/travel_rec/lib/python3.8/site-packages/pandas/core/arraylike.py:40\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__eq__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meq\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/travel_rec/lib/python3.8/site-packages/pandas/core/series.py:6096\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6093\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   6095\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 6096\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6098\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(res_values, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[0;32m~/miniconda3/envs/travel_rec/lib/python3.8/site-packages/pandas/core/ops/array_ops.py:293\u001b[0m, in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m invalid_comparison(lvalues, rvalues, op)\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_object_dtype(lvalues\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rvalues, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 293\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43mcomp_method_OBJECT_ARRAY\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    296\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m _na_arithmetic_op(lvalues, rvalues, op, is_cmp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/travel_rec/lib/python3.8/site-packages/pandas/core/ops/array_ops.py:82\u001b[0m, in \u001b[0;36mcomp_method_OBJECT_ARRAY\u001b[0;34m(op, x, y)\u001b[0m\n\u001b[1;32m     80\u001b[0m     result \u001b[38;5;241m=\u001b[39m libops\u001b[38;5;241m.\u001b[39mvec_compare(x\u001b[38;5;241m.\u001b[39mravel(), y\u001b[38;5;241m.\u001b[39mravel(), op)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 82\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mlibops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscalar_compare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mreshape(x\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 최적화된 버전 + 상세 진행도 표시\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 초기 설정\n",
    "df1 = df_original.copy()\n",
    "train_travel_ids = set()  # 이미 Train에 추가된 travel_id 집합\n",
    "Train = pd.DataFrame(columns=list(df_original.columns))\n",
    "\n",
    "# 진행 상황 표시 준비\n",
    "total_places = len(df_original['VISIT_AREA_NM'].unique())\n",
    "print(f\"총 관광지 수: {total_places}개\")\n",
    "\n",
    "# 관광지별 사용자 인덱스 미리 계산 (진행도 표시)\n",
    "print(\"관광지별 사용자 데이터 준비 중...\")\n",
    "place_to_users = {}\n",
    "for place in tqdm(df_original['VISIT_AREA_NM'].unique(), desc=\"관광지 맵핑\"):\n",
    "    place_to_users[place] = set(df_original[df_original['VISIT_AREA_NM'] == place]['TRAVEL_ID'])\n",
    "\n",
    "# 각 관광지마다 최소 1명의 유저를 Train set에 추가 (상세 진행도 추가)\n",
    "print(\"\\n각 관광지별 대표 사용자 추가 중...\")\n",
    "added_places = 0\n",
    "total_users_added = 0\n",
    "\n",
    "for place in tqdm(list(df_original['VISIT_AREA_NM'].unique()), desc=\"관광지 처리\"):\n",
    "    # 아직 Train에 추가되지 않은 이 관광지 방문자들\n",
    "    available_users = place_to_users[place] - train_travel_ids\n",
    "    \n",
    "    if not available_users:\n",
    "        continue\n",
    "    \n",
    "    # 랜덤하게 한 사용자 선택\n",
    "    np.random.seed(42)\n",
    "    selected_user = np.random.choice(list(available_users))\n",
    "    \n",
    "    # 선택된 사용자의 모든 방문 데이터 추가\n",
    "    user_data = df1[df1['TRAVEL_ID'] == selected_user]\n",
    "    Train = pd.concat([Train, user_data], ignore_index=True)\n",
    "    \n",
    "    # 추가된 사용자 ID 기록\n",
    "    train_travel_ids.add(selected_user)\n",
    "    \n",
    "    # df1에서 해당 사용자 데이터 제거\n",
    "    df1 = df1[df1['TRAVEL_ID'] != selected_user]\n",
    "    \n",
    "    # 상세 진행 상황 업데이트\n",
    "    added_places += 1\n",
    "    total_users_added += 1\n",
    "    \n",
    "    # 매 100개 관광지마다 상황 표시\n",
    "    if added_places % 100 == 0:\n",
    "        print(f\"진행 상황: {added_places}/{total_places} 관광지 처리 ({added_places/total_places*100:.1f}%)\")\n",
    "        print(f\"현재까지 {total_users_added}명의 사용자가 Train set에 추가됨\")\n",
    "        print(f\"Train set 크기: {len(Train)}, Test set 크기: {len(df1)}\")\n",
    "\n",
    "# 최종 결과 표시\n",
    "print(f\"\\n완료! 총 {added_places}개 관광지의 {total_users_added}명 사용자가 Train set에 추가됨\")\n",
    "print(f\"Train set 크기: {len(Train)}행 ({len(Train)/len(df_original)*100:.1f}%)\")\n",
    "print(f\"남은 Test set 크기: {len(df1)}행 ({len(df1)/len(df_original)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### 2.3 남은 유저들을 80:20 비율로 분할\n",
    "\n",
    "# %%\n",
    "# 80:20 비율 맞추기\n",
    "while len(df1)/len(df_original) > 0.2:\n",
    "    np.random.seed(42)\n",
    "    if len(df1) == 0:\n",
    "        break\n",
    "    random_number = np.random.randint(len(df1))\n",
    "    df_id = df1.iloc[[random_number]]\n",
    "    index = df_id.iloc[0,0]\n",
    "    df3 = df1[df1['TRAVEL_ID'] == index]\n",
    "    df1 = pd.merge(df3, df1, how='outer', indicator=True)\n",
    "    df1 = df1.query('_merge ==\"right_only\"').drop(columns=['_merge'])\n",
    "    Train = pd.concat([Train, df3], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set 크기: 745214 (80.0%)\n",
      "Test set 크기: 186295 (20.0%)\n",
      "Train set 관광지 수: 11467\n",
      "Test set 관광지 수: 1855\n",
      "Train set에만 있는 관광지 수: 9613\n",
      "Test set에만 있는 관광지 수: 1\n",
      "주의: Train set에 없는 관광지가 1개 있습니다.\n"
     ]
    }
   ],
   "source": [
    "# ### 2.4 분할 결과 확인\n",
    "\n",
    "# %%\n",
    "# 분할 결과 검증\n",
    "print(f\"Train set 크기: {len(Train)} ({len(Train)/len(df_original)*100:.1f}%)\")\n",
    "print(f\"Test set 크기: {len(df1)} ({len(df1)/len(df_original)*100:.1f}%)\")\n",
    "\n",
    "# 관광지 포함 여부 확인\n",
    "train_places = set(Train['VISIT_AREA_NM'].unique())\n",
    "test_places = set(df1['VISIT_AREA_NM'].unique())\n",
    "print(f\"Train set 관광지 수: {len(train_places)}\")\n",
    "print(f\"Test set 관광지 수: {len(test_places)}\")\n",
    "print(f\"Train set에만 있는 관광지 수: {len(train_places - test_places)}\")\n",
    "print(f\"Test set에만 있는 관광지 수: {len(test_places - train_places)}\")\n",
    "\n",
    "# 모든 관광지가 train set에 포함되었는지 확인\n",
    "all_places = set(df_original['VISIT_AREA_NM'].unique())\n",
    "missing_places = all_places - train_places\n",
    "if len(missing_places) > 0:\n",
    "    print(f\"주의: Train set에 없는 관광지가 {len(missing_places)}개 있습니다.\")\n",
    "else:\n",
    "    print(\"성공: 모든 관광지가 Train set에 포함되어 있습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11467/11467 [08:10<00:00, 23.36it/s]\n"
     ]
    }
   ],
   "source": [
    "# ## 3. 관광지별 통계 계산 (기본 + 확장 특성)\n",
    "\n",
    "# %%\n",
    "# 3.1 통계 계산을 위한 기본 컬럼 정의\n",
    "basic_stat_columns = [\n",
    "    'RESIDENCE_TIME_MIN',      # 체류시간\n",
    "    'RCMDTN_INTENTION',        # 추천의향\n",
    "    'REVISIT_YN',              # 재방문여부\n",
    "    'TRAVEL_COMPANIONS_NUM',   # 동반자 수\n",
    "    'REVISIT_INTENTION',       # 재방문의향\n",
    "    'DGSTFN'                   # 만족도\n",
    "]\n",
    "\n",
    "# %% [markdown]\n",
    "# ### 3.2 기본 통계값 계산\n",
    "\n",
    "# %%\n",
    "# 새로운 데이터프레임 생성\n",
    "stat_columns = [f'{col}_mean' for col in basic_stat_columns]\n",
    "new_train = pd.DataFrame(columns=list(Train.columns) + stat_columns)\n",
    "\n",
    "# 각 관광지별 기본 통계 계산\n",
    "for i in tqdm(list(Train['VISIT_AREA_NM'].unique())):\n",
    "    df2 = Train[Train['VISIT_AREA_NM'] == i]\n",
    "    \n",
    "    # 기본 통계값 계산\n",
    "    for j in basic_stat_columns:\n",
    "        mean_value = df2[j].mean()\n",
    "        df2[f'{j}_mean'] = mean_value\n",
    "    \n",
    "    # 새로운 데이터프레임에 추가\n",
    "    new_train = pd.concat([new_train, df2], axis=0)\n",
    "\n",
    "# 정렬 및 인덱스 재설정\n",
    "new_train.sort_values(by=['TRAVEL_ID'], axis=0, inplace=True)\n",
    "new_train.reset_index(drop=True, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ### 3.3 확장된 특성 통계 계산 - 방문객 특성별 분포\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# %%\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# 방문지별 통계 데이터프레임 생성\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m place_stats \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[1;32m      6\u001b[0m place_stats[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVISIT_AREA_NM\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m Train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVISIT_AREA_NM\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39munique()\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# %% [markdown]\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# #### 3.3.1 성별, 연령대, 소득 분포\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# %%\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# 성별 분포\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# ### 3.3 확장된 특성 통계 계산 - 방문객 특성별 분포\n",
    "\n",
    "# %%\n",
    "# 방문지별 통계 데이터프레임 생성\n",
    "place_stats = pd.DataFrame()\n",
    "place_stats['VISIT_AREA_NM'] = Train['VISIT_AREA_NM'].unique()\n",
    "\n",
    "# %% [markdown]\n",
    "# #### 3.3.1 성별, 연령대, 소득 분포\n",
    "\n",
    "# %%\n",
    "# 성별 분포\n",
    "gender_pivot = pd.pivot_table(\n",
    "    Train, \n",
    "    values='TRAVEL_ID', \n",
    "    index='VISIT_AREA_NM', \n",
    "    columns='GENDER', \n",
    "    aggfunc='count',\n",
    "    fill_value=0\n",
    ")\n",
    "gender_pivot = gender_pivot.div(gender_pivot.sum(axis=1), axis=0)\n",
    "gender_pivot.columns = [f'GENDER_RATIO_{col}' for col in gender_pivot.columns]\n",
    "place_stats = place_stats.merge(gender_pivot.reset_index(), on='VISIT_AREA_NM', how='left')\n",
    "\n",
    "# 연령대 분포\n",
    "age_pivot = pd.pivot_table(\n",
    "    Train, \n",
    "    values='TRAVEL_ID', \n",
    "    index='VISIT_AREA_NM', \n",
    "    columns='AGE_GRP', \n",
    "    aggfunc='count',\n",
    "    fill_value=0\n",
    ")\n",
    "age_pivot = age_pivot.div(age_pivot.sum(axis=1), axis=0)\n",
    "age_pivot.columns = [f'AGE_RATIO_{col}' for col in age_pivot.columns]\n",
    "place_stats = place_stats.merge(age_pivot.reset_index(), on='VISIT_AREA_NM', how='left')\n",
    "\n",
    "# 소득 분포\n",
    "income_pivot = pd.pivot_table(\n",
    "    Train, \n",
    "    values='TRAVEL_ID', \n",
    "    index='VISIT_AREA_NM', \n",
    "    columns='INCOME', \n",
    "    aggfunc='count',\n",
    "    fill_value=0\n",
    ")\n",
    "income_pivot = income_pivot.div(income_pivot.sum(axis=1), axis=0)\n",
    "income_pivot.columns = [f'INCOME_RATIO_{col}' for col in income_pivot.columns]\n",
    "place_stats = place_stats.merge(income_pivot.reset_index(), on='VISIT_AREA_NM', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### 3.3.2 여행 목적 및 여행 스타일 분포\n",
    "\n",
    "# %%\n",
    "# 여행 목적(미션) 분포\n",
    "mission_pivot = pd.pivot_table(\n",
    "    Train, \n",
    "    values='TRAVEL_ID', \n",
    "    index='VISIT_AREA_NM', \n",
    "    columns='TRAVEL_MISSION_PRIORITY', \n",
    "    aggfunc='count',\n",
    "    fill_value=0\n",
    ")\n",
    "mission_pivot = mission_pivot.div(mission_pivot.sum(axis=1), axis=0)\n",
    "mission_pivot.columns = [f'MISSION_RATIO_{col}' for col in mission_pivot.columns]\n",
    "place_stats = place_stats.merge(mission_pivot.reset_index(), on='VISIT_AREA_NM', how='left')\n",
    "\n",
    "# 여행 동기 분포\n",
    "motive_pivot = pd.pivot_table(\n",
    "    Train, \n",
    "    values='TRAVEL_ID', \n",
    "    index='VISIT_AREA_NM', \n",
    "    columns='TRAVEL_MOTIVE_1', \n",
    "    aggfunc='count',\n",
    "    fill_value=0\n",
    ")\n",
    "motive_pivot = motive_pivot.div(motive_pivot.sum(axis=1), axis=0)\n",
    "motive_pivot.columns = [f'MOTIVE_RATIO_{col}' for col in motive_pivot.columns]\n",
    "place_stats = place_stats.merge(motive_pivot.reset_index(), on='VISIT_AREA_NM', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### 3.3.3 여행 스타일 평균값 계산\n",
    "\n",
    "# %%\n",
    "# 여행 스타일 평균값\n",
    "for i in range(1, 9):\n",
    "    style_col = f'TRAVEL_STYL_{i}'\n",
    "    style_means = Train.groupby('VISIT_AREA_NM')[style_col].mean()\n",
    "    style_means.name = f'{style_col}_mean'\n",
    "    place_stats = place_stats.merge(style_means.reset_index(), on='VISIT_AREA_NM', how='left')\n",
    "\n",
    "# %% [markdown]\n",
    "# #### 3.3.4 관광지 방문 빈도 및 유형 통계\n",
    "\n",
    "# %%\n",
    "# 방문 빈도\n",
    "visit_counts = Train.groupby('VISIT_AREA_NM').size().rename('VISIT_FREQUENCY')\n",
    "place_stats = place_stats.merge(visit_counts.reset_index(), on='VISIT_AREA_NM', how='left')\n",
    "\n",
    "# 관광지 유형 분포\n",
    "area_type_pivot = pd.pivot_table(\n",
    "    Train, \n",
    "    values='TRAVEL_ID', \n",
    "    index='VISIT_AREA_NM', \n",
    "    columns='VISIT_AREA_TYPE_CD', \n",
    "    aggfunc='count',\n",
    "    fill_value=0\n",
    ")\n",
    "area_type_pivot = area_type_pivot.div(area_type_pivot.sum(axis=1), axis=0)\n",
    "area_type_pivot.columns = [f'AREA_TYPE_RATIO_{col}' for col in area_type_pivot.columns]\n",
    "place_stats = place_stats.merge(area_type_pivot.reset_index(), on='VISIT_AREA_NM', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### 3.3.5 지역 정보 통계\n",
    "\n",
    "# %%\n",
    "# 시도별 방문 비율\n",
    "sido_pivot = pd.pivot_table(\n",
    "    Train, \n",
    "    values='TRAVEL_ID', \n",
    "    index='VISIT_AREA_NM', \n",
    "    columns='SIDO', \n",
    "    aggfunc='count',\n",
    "    fill_value=0\n",
    ")\n",
    "sido_pivot = sido_pivot.div(sido_pivot.sum(axis=1), axis=0)\n",
    "sido_pivot.columns = [f'SIDO_RATIO_{col}' for col in sido_pivot.columns]\n",
    "place_stats = place_stats.merge(sido_pivot.reset_index(), on='VISIT_AREA_NM', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### 3.3.6 동반자 유형 통계 (REL_CD가 있는 경우)\n",
    "\n",
    "# %%\n",
    "# 동반자 데이터가 있는 경우에만 실행\n",
    "if 'REL_CD' in Train.columns:\n",
    "    rel_pivot = pd.pivot_table(\n",
    "        Train, \n",
    "        values='TRAVEL_ID', \n",
    "        index='VISIT_AREA_NM', \n",
    "        columns='REL_CD', \n",
    "        aggfunc='count',\n",
    "        fill_value=0\n",
    "    )\n",
    "    rel_pivot = rel_pivot.div(rel_pivot.sum(axis=1), axis=0)\n",
    "    rel_pivot.columns = [f'REL_CD_RATIO_{col}' for col in rel_pivot.columns]\n",
    "    place_stats = place_stats.merge(rel_pivot.reset_index(), on='VISIT_AREA_NM', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### 3.3.7 지출 패턴 통계 (소비 내역 데이터가 있는 경우)\n",
    "\n",
    "# %%\n",
    "# 소비 내역 데이터가 있는 경우에만 실행\n",
    "if 'ACTIVITY_TYPE_CD' in Train.columns:\n",
    "    activity_pivot = pd.pivot_table(\n",
    "        Train, \n",
    "        values='TRAVEL_ID', \n",
    "        index='VISIT_AREA_NM', \n",
    "        columns='ACTIVITY_TYPE_CD', \n",
    "        aggfunc='count',\n",
    "        fill_value=0\n",
    "    )\n",
    "    activity_pivot = activity_pivot.div(activity_pivot.sum(axis=1), axis=0)\n",
    "    activity_pivot.columns = [f'ACTIVITY_RATIO_{col}' for col in activity_pivot.columns]\n",
    "    place_stats = place_stats.merge(activity_pivot.reset_index(), on='VISIT_AREA_NM', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### 3.3.8 이동수단 선호도 통계 (이동수단 데이터가 있는 경우)\n",
    "\n",
    "# %%\n",
    "# 이동수단 데이터가 있는 경우에만 실행\n",
    "if 'MVMN_SE_NM' in Train.columns:\n",
    "    mvmn_pivot = pd.pivot_table(\n",
    "        Train, \n",
    "        values='TRAVEL_ID', \n",
    "        index='VISIT_AREA_NM', \n",
    "        columns='MVMN_SE_NM', \n",
    "        aggfunc='count',\n",
    "        fill_value=0\n",
    "    )\n",
    "    mvmn_pivot = mvmn_pivot.div(mvmn_pivot.sum(axis=1), axis=0)\n",
    "    mvmn_pivot.columns = [f'TRANSPORT_RATIO_{col}' for col in mvmn_pivot.columns]\n",
    "    place_stats = place_stats.merge(mvmn_pivot.reset_index(), on='VISIT_AREA_NM', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "계산된 관광지별 통계 수: 11467\n",
      "통계 특성 수: 125\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VISIT_AREA_NM</th>\n",
       "      <th>GENDER_RATIO_남</th>\n",
       "      <th>GENDER_RATIO_여</th>\n",
       "      <th>AGE_RATIO_20</th>\n",
       "      <th>AGE_RATIO_30</th>\n",
       "      <th>AGE_RATIO_40</th>\n",
       "      <th>AGE_RATIO_50</th>\n",
       "      <th>AGE_RATIO_60</th>\n",
       "      <th>INCOME_RATIO_1</th>\n",
       "      <th>INCOME_RATIO_2</th>\n",
       "      <th>INCOME_RATIO_3</th>\n",
       "      <th>INCOME_RATIO_4</th>\n",
       "      <th>INCOME_RATIO_5</th>\n",
       "      <th>INCOME_RATIO_6</th>\n",
       "      <th>INCOME_RATIO_7</th>\n",
       "      <th>INCOME_RATIO_8</th>\n",
       "      <th>INCOME_RATIO_9</th>\n",
       "      <th>INCOME_RATIO_10</th>\n",
       "      <th>INCOME_RATIO_11</th>\n",
       "      <th>INCOME_RATIO_12</th>\n",
       "      <th>MISSION_RATIO_1</th>\n",
       "      <th>MISSION_RATIO_2</th>\n",
       "      <th>MISSION_RATIO_3</th>\n",
       "      <th>MISSION_RATIO_4</th>\n",
       "      <th>MISSION_RATIO_5</th>\n",
       "      <th>MISSION_RATIO_6</th>\n",
       "      <th>MISSION_RATIO_7</th>\n",
       "      <th>MISSION_RATIO_8</th>\n",
       "      <th>MISSION_RATIO_9</th>\n",
       "      <th>MISSION_RATIO_10</th>\n",
       "      <th>MISSION_RATIO_11</th>\n",
       "      <th>MISSION_RATIO_12</th>\n",
       "      <th>MISSION_RATIO_13</th>\n",
       "      <th>MISSION_RATIO_21</th>\n",
       "      <th>MISSION_RATIO_22</th>\n",
       "      <th>MISSION_RATIO_23</th>\n",
       "      <th>MISSION_RATIO_24</th>\n",
       "      <th>MISSION_RATIO_25</th>\n",
       "      <th>MISSION_RATIO_26</th>\n",
       "      <th>MISSION_RATIO_27</th>\n",
       "      <th>MISSION_RATIO_28</th>\n",
       "      <th>MOTIVE_RATIO_1</th>\n",
       "      <th>MOTIVE_RATIO_2</th>\n",
       "      <th>MOTIVE_RATIO_3</th>\n",
       "      <th>MOTIVE_RATIO_4</th>\n",
       "      <th>MOTIVE_RATIO_5</th>\n",
       "      <th>MOTIVE_RATIO_6</th>\n",
       "      <th>MOTIVE_RATIO_7</th>\n",
       "      <th>MOTIVE_RATIO_8</th>\n",
       "      <th>MOTIVE_RATIO_9</th>\n",
       "      <th>MOTIVE_RATIO_10</th>\n",
       "      <th>TRAVEL_STYL_1_mean</th>\n",
       "      <th>TRAVEL_STYL_2_mean</th>\n",
       "      <th>TRAVEL_STYL_3_mean</th>\n",
       "      <th>TRAVEL_STYL_4_mean</th>\n",
       "      <th>TRAVEL_STYL_5_mean</th>\n",
       "      <th>TRAVEL_STYL_6_mean</th>\n",
       "      <th>TRAVEL_STYL_7_mean</th>\n",
       "      <th>TRAVEL_STYL_8_mean</th>\n",
       "      <th>VISIT_FREQUENCY</th>\n",
       "      <th>AREA_TYPE_RATIO_1.0</th>\n",
       "      <th>AREA_TYPE_RATIO_2.0</th>\n",
       "      <th>AREA_TYPE_RATIO_3.0</th>\n",
       "      <th>AREA_TYPE_RATIO_4.0</th>\n",
       "      <th>AREA_TYPE_RATIO_5.0</th>\n",
       "      <th>AREA_TYPE_RATIO_6.0</th>\n",
       "      <th>AREA_TYPE_RATIO_7.0</th>\n",
       "      <th>AREA_TYPE_RATIO_8.0</th>\n",
       "      <th>SIDO_RATIO_강원</th>\n",
       "      <th>SIDO_RATIO_강원도</th>\n",
       "      <th>SIDO_RATIO_강원특별자치도</th>\n",
       "      <th>SIDO_RATIO_경기</th>\n",
       "      <th>SIDO_RATIO_경기도</th>\n",
       "      <th>SIDO_RATIO_경남</th>\n",
       "      <th>SIDO_RATIO_경북</th>\n",
       "      <th>SIDO_RATIO_경상남도</th>\n",
       "      <th>SIDO_RATIO_경상북도</th>\n",
       "      <th>SIDO_RATIO_광주</th>\n",
       "      <th>SIDO_RATIO_대구</th>\n",
       "      <th>SIDO_RATIO_대전</th>\n",
       "      <th>SIDO_RATIO_대전광역시</th>\n",
       "      <th>SIDO_RATIO_부산</th>\n",
       "      <th>SIDO_RATIO_부산광역시</th>\n",
       "      <th>SIDO_RATIO_서울</th>\n",
       "      <th>SIDO_RATIO_서울특별시</th>\n",
       "      <th>SIDO_RATIO_세종특별자치시</th>\n",
       "      <th>SIDO_RATIO_울산</th>\n",
       "      <th>SIDO_RATIO_인천</th>\n",
       "      <th>SIDO_RATIO_전남</th>\n",
       "      <th>SIDO_RATIO_전라남도</th>\n",
       "      <th>SIDO_RATIO_전라북도</th>\n",
       "      <th>SIDO_RATIO_전북</th>\n",
       "      <th>SIDO_RATIO_제주특별자치도</th>\n",
       "      <th>SIDO_RATIO_충남</th>\n",
       "      <th>SIDO_RATIO_충북</th>\n",
       "      <th>SIDO_RATIO_충청남도</th>\n",
       "      <th>SIDO_RATIO_충청북도</th>\n",
       "      <th>REL_CD_RATIO_1.0</th>\n",
       "      <th>REL_CD_RATIO_2.0</th>\n",
       "      <th>REL_CD_RATIO_3.0</th>\n",
       "      <th>REL_CD_RATIO_4.0</th>\n",
       "      <th>REL_CD_RATIO_5.0</th>\n",
       "      <th>REL_CD_RATIO_6.0</th>\n",
       "      <th>REL_CD_RATIO_7.0</th>\n",
       "      <th>REL_CD_RATIO_8.0</th>\n",
       "      <th>REL_CD_RATIO_9.0</th>\n",
       "      <th>REL_CD_RATIO_10.0</th>\n",
       "      <th>ACTIVITY_RATIO_1.0</th>\n",
       "      <th>ACTIVITY_RATIO_2.0</th>\n",
       "      <th>ACTIVITY_RATIO_3.0</th>\n",
       "      <th>ACTIVITY_RATIO_6.0</th>\n",
       "      <th>TRANSPORT_RATIO_KTX/SRT(고속열차)</th>\n",
       "      <th>TRANSPORT_RATIO_관광버스</th>\n",
       "      <th>TRANSPORT_RATIO_기타</th>\n",
       "      <th>TRANSPORT_RATIO_렌터카(승용/승합/버스 등등)</th>\n",
       "      <th>TRANSPORT_RATIO_배/선박</th>\n",
       "      <th>TRANSPORT_RATIO_버스 + 지하철</th>\n",
       "      <th>TRANSPORT_RATIO_새마을/무궁화열차</th>\n",
       "      <th>TRANSPORT_RATIO_시내/마을버스</th>\n",
       "      <th>TRANSPORT_RATIO_시외/고속버스</th>\n",
       "      <th>TRANSPORT_RATIO_자가용(승용/승합/트럭 등등)</th>\n",
       "      <th>TRANSPORT_RATIO_자전거</th>\n",
       "      <th>TRANSPORT_RATIO_지하철</th>\n",
       "      <th>TRANSPORT_RATIO_캠핑카(자차 및 렌탈)</th>\n",
       "      <th>TRANSPORT_RATIO_택시</th>\n",
       "      <th>TRANSPORT_RATIO_항공기</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>화성 관광열차 안내소 연무대 매표소</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>화성행궁</td>\n",
       "      <td>0.297357</td>\n",
       "      <td>0.702643</td>\n",
       "      <td>0.612335</td>\n",
       "      <td>0.224670</td>\n",
       "      <td>0.081498</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.081498</td>\n",
       "      <td>0.070485</td>\n",
       "      <td>0.123348</td>\n",
       "      <td>0.211454</td>\n",
       "      <td>0.436123</td>\n",
       "      <td>0.085903</td>\n",
       "      <td>0.035242</td>\n",
       "      <td>0.037445</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.134361</td>\n",
       "      <td>0.017621</td>\n",
       "      <td>0.574890</td>\n",
       "      <td>0.037445</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.013216</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.035242</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011013</td>\n",
       "      <td>0.176211</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.314978</td>\n",
       "      <td>0.138767</td>\n",
       "      <td>0.182819</td>\n",
       "      <td>0.055066</td>\n",
       "      <td>0.033040</td>\n",
       "      <td>0.022026</td>\n",
       "      <td>0.136564</td>\n",
       "      <td>0.092511</td>\n",
       "      <td>0.024229</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.596916</td>\n",
       "      <td>3.185022</td>\n",
       "      <td>3.220264</td>\n",
       "      <td>3.535242</td>\n",
       "      <td>3.60793</td>\n",
       "      <td>4.299559</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.414097</td>\n",
       "      <td>454</td>\n",
       "      <td>0.008811</td>\n",
       "      <td>0.95815</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.087533</td>\n",
       "      <td>0.135279</td>\n",
       "      <td>0.029178</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.336870</td>\n",
       "      <td>0.376658</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.634361</td>\n",
       "      <td>0.165198</td>\n",
       "      <td>0.176211</td>\n",
       "      <td>0.024229</td>\n",
       "      <td>0.052863</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.196035</td>\n",
       "      <td>0.059471</td>\n",
       "      <td>0.077093</td>\n",
       "      <td>0.088106</td>\n",
       "      <td>0.251101</td>\n",
       "      <td>0.013216</td>\n",
       "      <td>0.143172</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.118943</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>수원 화성 북서적대</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>에버랜드</td>\n",
       "      <td>0.199387</td>\n",
       "      <td>0.800613</td>\n",
       "      <td>0.423313</td>\n",
       "      <td>0.487730</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042945</td>\n",
       "      <td>0.046012</td>\n",
       "      <td>0.162577</td>\n",
       "      <td>0.312883</td>\n",
       "      <td>0.067485</td>\n",
       "      <td>0.260736</td>\n",
       "      <td>0.119632</td>\n",
       "      <td>0.039877</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.03681</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.067485</td>\n",
       "      <td>0.760736</td>\n",
       "      <td>0.082822</td>\n",
       "      <td>0.088957</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.506135</td>\n",
       "      <td>0.055215</td>\n",
       "      <td>0.095092</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.088957</td>\n",
       "      <td>0.055215</td>\n",
       "      <td>0.199387</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.389571</td>\n",
       "      <td>1.711656</td>\n",
       "      <td>1.932515</td>\n",
       "      <td>3.773006</td>\n",
       "      <td>3.831288</td>\n",
       "      <td>3.174847</td>\n",
       "      <td>4.472393</td>\n",
       "      <td>6.226994</td>\n",
       "      <td>326</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.149466</td>\n",
       "      <td>0.163701</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.370107</td>\n",
       "      <td>0.316726</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.641104</td>\n",
       "      <td>0.165644</td>\n",
       "      <td>0.144172</td>\n",
       "      <td>0.049080</td>\n",
       "      <td>0.065831</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.037618</td>\n",
       "      <td>0.018809</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.184953</td>\n",
       "      <td>0.075235</td>\n",
       "      <td>0.015674</td>\n",
       "      <td>0.028213</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>0.040752</td>\n",
       "      <td>0.021944</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.131661</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>못골종합시장</td>\n",
       "      <td>0.056604</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>0.735849</td>\n",
       "      <td>0.207547</td>\n",
       "      <td>0.056604</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.735849</td>\n",
       "      <td>0.207547</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056604</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.207547</td>\n",
       "      <td>0.735849</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.056604</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.207547</td>\n",
       "      <td>0.056604</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.735849</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.622642</td>\n",
       "      <td>2.09434</td>\n",
       "      <td>2.415094</td>\n",
       "      <td>2.377358</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.056604</td>\n",
       "      <td>3.037736</td>\n",
       "      <td>6.301887</td>\n",
       "      <td>53</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.207547</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.584906</td>\n",
       "      <td>0.226415</td>\n",
       "      <td>0.132075</td>\n",
       "      <td>0.056604</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.245283</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.207547</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.245283</td>\n",
       "      <td>0.056604</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.245283</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         VISIT_AREA_NM  GENDER_RATIO_남  GENDER_RATIO_여  AGE_RATIO_20  \\\n",
       "0  화성 관광열차 안내소 연무대 매표소        0.000000        1.000000      0.000000   \n",
       "1                 화성행궁        0.297357        0.702643      0.612335   \n",
       "2           수원 화성 북서적대        0.000000        1.000000      0.000000   \n",
       "3                 에버랜드        0.199387        0.800613      0.423313   \n",
       "4               못골종합시장        0.056604        0.943396      0.735849   \n",
       "\n",
       "   AGE_RATIO_30  AGE_RATIO_40  AGE_RATIO_50  AGE_RATIO_60  INCOME_RATIO_1  \\\n",
       "0      0.000000      1.000000      0.000000      0.000000        1.000000   \n",
       "1      0.224670      0.081498      0.000000      0.081498        0.070485   \n",
       "2      0.000000      1.000000      0.000000      0.000000        1.000000   \n",
       "3      0.487730      0.000000      0.042945      0.046012        0.162577   \n",
       "4      0.207547      0.056604      0.000000      0.000000        0.000000   \n",
       "\n",
       "   INCOME_RATIO_2  INCOME_RATIO_3  INCOME_RATIO_4  INCOME_RATIO_5  \\\n",
       "0        0.000000        0.000000        0.000000        0.000000   \n",
       "1        0.123348        0.211454        0.436123        0.085903   \n",
       "2        0.000000        0.000000        0.000000        0.000000   \n",
       "3        0.312883        0.067485        0.260736        0.119632   \n",
       "4        0.735849        0.207547        0.000000        0.000000   \n",
       "\n",
       "   INCOME_RATIO_6  INCOME_RATIO_7  INCOME_RATIO_8  INCOME_RATIO_9  \\\n",
       "0        0.000000        0.000000         0.00000             0.0   \n",
       "1        0.035242        0.037445         0.00000             0.0   \n",
       "2        0.000000        0.000000         0.00000             0.0   \n",
       "3        0.039877        0.000000         0.03681             0.0   \n",
       "4        0.000000        0.056604         0.00000             0.0   \n",
       "\n",
       "   INCOME_RATIO_10  INCOME_RATIO_11  INCOME_RATIO_12  MISSION_RATIO_1  \\\n",
       "0              0.0              0.0              0.0         0.000000   \n",
       "1              0.0              0.0              0.0         0.134361   \n",
       "2              0.0              0.0              0.0         0.000000   \n",
       "3              0.0              0.0              0.0         0.067485   \n",
       "4              0.0              0.0              0.0         0.207547   \n",
       "\n",
       "   MISSION_RATIO_2  MISSION_RATIO_3  MISSION_RATIO_4  MISSION_RATIO_5  \\\n",
       "0         0.000000         1.000000         0.000000              0.0   \n",
       "1         0.017621         0.574890         0.037445              0.0   \n",
       "2         0.000000         1.000000         0.000000              0.0   \n",
       "3         0.760736         0.082822         0.088957              0.0   \n",
       "4         0.735849         0.000000         0.000000              0.0   \n",
       "\n",
       "   MISSION_RATIO_6  MISSION_RATIO_7  MISSION_RATIO_8  MISSION_RATIO_9  \\\n",
       "0         0.000000              0.0              0.0              0.0   \n",
       "1         0.013216              0.0              0.0              0.0   \n",
       "2         0.000000              0.0              0.0              0.0   \n",
       "3         0.000000              0.0              0.0              0.0   \n",
       "4         0.056604              0.0              0.0              0.0   \n",
       "\n",
       "   MISSION_RATIO_10  MISSION_RATIO_11  MISSION_RATIO_12  MISSION_RATIO_13  \\\n",
       "0               0.0               0.0          0.000000               0.0   \n",
       "1               0.0               0.0          0.035242               0.0   \n",
       "2               0.0               0.0          0.000000               0.0   \n",
       "3               0.0               0.0          0.000000               0.0   \n",
       "4               0.0               0.0          0.000000               0.0   \n",
       "\n",
       "   MISSION_RATIO_21  MISSION_RATIO_22  MISSION_RATIO_23  MISSION_RATIO_24  \\\n",
       "0          0.000000          0.000000               0.0               0.0   \n",
       "1          0.011013          0.176211               0.0               0.0   \n",
       "2          0.000000          0.000000               0.0               0.0   \n",
       "3          0.000000          0.000000               0.0               0.0   \n",
       "4          0.000000          0.000000               0.0               0.0   \n",
       "\n",
       "   MISSION_RATIO_25  MISSION_RATIO_26  MISSION_RATIO_27  MISSION_RATIO_28  \\\n",
       "0               0.0               0.0               0.0               0.0   \n",
       "1               0.0               0.0               0.0               0.0   \n",
       "2               0.0               0.0               0.0               0.0   \n",
       "3               0.0               0.0               0.0               0.0   \n",
       "4               0.0               0.0               0.0               0.0   \n",
       "\n",
       "   MOTIVE_RATIO_1  MOTIVE_RATIO_2  MOTIVE_RATIO_3  MOTIVE_RATIO_4  \\\n",
       "0        0.000000        0.000000        0.000000        0.000000   \n",
       "1        0.314978        0.138767        0.182819        0.055066   \n",
       "2        0.000000        0.000000        0.000000        0.000000   \n",
       "3        0.506135        0.055215        0.095092        0.000000   \n",
       "4        0.000000        0.000000        0.207547        0.056604   \n",
       "\n",
       "   MOTIVE_RATIO_5  MOTIVE_RATIO_6  MOTIVE_RATIO_7  MOTIVE_RATIO_8  \\\n",
       "0        0.000000        0.000000        0.000000        1.000000   \n",
       "1        0.033040        0.022026        0.136564        0.092511   \n",
       "2        0.000000        0.000000        0.000000        1.000000   \n",
       "3        0.088957        0.055215        0.199387        0.000000   \n",
       "4        0.000000        0.000000        0.735849        0.000000   \n",
       "\n",
       "   MOTIVE_RATIO_9  MOTIVE_RATIO_10 TRAVEL_STYL_1_mean TRAVEL_STYL_2_mean  \\\n",
       "0        0.000000              0.0                4.0                3.0   \n",
       "1        0.024229              0.0           3.596916           3.185022   \n",
       "2        0.000000              0.0                4.0                3.0   \n",
       "3        0.000000              0.0           3.389571           1.711656   \n",
       "4        0.000000              0.0           5.622642            2.09434   \n",
       "\n",
       "  TRAVEL_STYL_3_mean TRAVEL_STYL_4_mean TRAVEL_STYL_5_mean TRAVEL_STYL_6_mean  \\\n",
       "0                5.0                2.0                3.0                6.0   \n",
       "1           3.220264           3.535242            3.60793           4.299559   \n",
       "2                5.0                2.0                3.0                6.0   \n",
       "3           1.932515           3.773006           3.831288           3.174847   \n",
       "4           2.415094           2.377358                3.0           3.056604   \n",
       "\n",
       "  TRAVEL_STYL_7_mean TRAVEL_STYL_8_mean  VISIT_FREQUENCY  AREA_TYPE_RATIO_1.0  \\\n",
       "0                5.0                6.0               10             0.000000   \n",
       "1                4.0           4.414097              454             0.008811   \n",
       "2                5.0                6.0               10             0.000000   \n",
       "3           4.472393           6.226994              326             0.000000   \n",
       "4           3.037736           6.301887               53             0.000000   \n",
       "\n",
       "   AREA_TYPE_RATIO_2.0  AREA_TYPE_RATIO_3.0  AREA_TYPE_RATIO_4.0  \\\n",
       "0              1.00000                  0.0                  0.0   \n",
       "1              0.95815                  0.0                  0.0   \n",
       "2              0.00000                  0.0                  0.0   \n",
       "3              0.00000                  0.0                  0.0   \n",
       "4              0.00000                  0.0                  1.0   \n",
       "\n",
       "   AREA_TYPE_RATIO_5.0  AREA_TYPE_RATIO_6.0  AREA_TYPE_RATIO_7.0  \\\n",
       "0                  0.0                  0.0                  0.0   \n",
       "1                  0.0                  0.0                  0.0   \n",
       "2                  0.0                  0.0                  1.0   \n",
       "3                  0.0                  1.0                  0.0   \n",
       "4                  0.0                  0.0                  0.0   \n",
       "\n",
       "   AREA_TYPE_RATIO_8.0  SIDO_RATIO_강원  SIDO_RATIO_강원도  SIDO_RATIO_강원특별자치도  \\\n",
       "0              0.00000            0.0             0.0                 0.0   \n",
       "1              0.03304            0.0             0.0                 0.0   \n",
       "2              0.00000            0.0             0.0                 0.0   \n",
       "3              0.00000            0.0             0.0                 0.0   \n",
       "4              0.00000            0.0             0.0                 0.0   \n",
       "\n",
       "   SIDO_RATIO_경기  SIDO_RATIO_경기도  SIDO_RATIO_경남  SIDO_RATIO_경북  \\\n",
       "0            1.0             0.0            0.0            0.0   \n",
       "1            1.0             0.0            0.0            0.0   \n",
       "2            1.0             0.0            0.0            0.0   \n",
       "3            1.0             0.0            0.0            0.0   \n",
       "4            1.0             0.0            0.0            0.0   \n",
       "\n",
       "   SIDO_RATIO_경상남도  SIDO_RATIO_경상북도  SIDO_RATIO_광주  SIDO_RATIO_대구  \\\n",
       "0              0.0              0.0            0.0            0.0   \n",
       "1              0.0              0.0            0.0            0.0   \n",
       "2              0.0              0.0            0.0            0.0   \n",
       "3              0.0              0.0            0.0            0.0   \n",
       "4              0.0              0.0            0.0            0.0   \n",
       "\n",
       "   SIDO_RATIO_대전  SIDO_RATIO_대전광역시  SIDO_RATIO_부산  SIDO_RATIO_부산광역시  \\\n",
       "0            0.0               0.0            0.0               0.0   \n",
       "1            0.0               0.0            0.0               0.0   \n",
       "2            0.0               0.0            0.0               0.0   \n",
       "3            0.0               0.0            0.0               0.0   \n",
       "4            0.0               0.0            0.0               0.0   \n",
       "\n",
       "   SIDO_RATIO_서울  SIDO_RATIO_서울특별시  SIDO_RATIO_세종특별자치시  SIDO_RATIO_울산  \\\n",
       "0            0.0               0.0                 0.0            0.0   \n",
       "1            0.0               0.0                 0.0            0.0   \n",
       "2            0.0               0.0                 0.0            0.0   \n",
       "3            0.0               0.0                 0.0            0.0   \n",
       "4            0.0               0.0                 0.0            0.0   \n",
       "\n",
       "   SIDO_RATIO_인천  SIDO_RATIO_전남  SIDO_RATIO_전라남도  SIDO_RATIO_전라북도  \\\n",
       "0            0.0            0.0              0.0              0.0   \n",
       "1            0.0            0.0              0.0              0.0   \n",
       "2            0.0            0.0              0.0              0.0   \n",
       "3            0.0            0.0              0.0              0.0   \n",
       "4            0.0            0.0              0.0              0.0   \n",
       "\n",
       "   SIDO_RATIO_전북  SIDO_RATIO_제주특별자치도  SIDO_RATIO_충남  SIDO_RATIO_충북  \\\n",
       "0            0.0                 0.0            0.0            0.0   \n",
       "1            0.0                 0.0            0.0            0.0   \n",
       "2            0.0                 0.0            0.0            0.0   \n",
       "3            0.0                 0.0            0.0            0.0   \n",
       "4            0.0                 0.0            0.0            0.0   \n",
       "\n",
       "   SIDO_RATIO_충청남도  SIDO_RATIO_충청북도  REL_CD_RATIO_1.0  REL_CD_RATIO_2.0  \\\n",
       "0              0.0              0.0          0.500000          0.500000   \n",
       "1              0.0              0.0          0.087533          0.135279   \n",
       "2              0.0              0.0          0.500000          0.500000   \n",
       "3              0.0              0.0          0.149466          0.163701   \n",
       "4              0.0              0.0          0.000000          0.000000   \n",
       "\n",
       "   REL_CD_RATIO_3.0  REL_CD_RATIO_4.0  REL_CD_RATIO_5.0  REL_CD_RATIO_6.0  \\\n",
       "0          0.000000               0.0          0.000000               0.0   \n",
       "1          0.029178               0.0          0.034483               0.0   \n",
       "2          0.000000               0.0          0.000000               0.0   \n",
       "3          0.000000               0.0          0.000000               0.0   \n",
       "4          0.000000               0.0          0.000000               0.0   \n",
       "\n",
       "   REL_CD_RATIO_7.0  REL_CD_RATIO_8.0  REL_CD_RATIO_9.0  REL_CD_RATIO_10.0  \\\n",
       "0          0.000000          0.000000               0.0                0.0   \n",
       "1          0.336870          0.376658               0.0                0.0   \n",
       "2          0.000000          0.000000               0.0                0.0   \n",
       "3          0.370107          0.316726               0.0                0.0   \n",
       "4          0.792453          0.207547               0.0                0.0   \n",
       "\n",
       "   ACTIVITY_RATIO_1.0  ACTIVITY_RATIO_2.0  ACTIVITY_RATIO_3.0  \\\n",
       "0            0.600000            0.000000            0.400000   \n",
       "1            0.634361            0.165198            0.176211   \n",
       "2            0.600000            0.000000            0.400000   \n",
       "3            0.641104            0.165644            0.144172   \n",
       "4            0.584906            0.226415            0.132075   \n",
       "\n",
       "   ACTIVITY_RATIO_6.0  TRANSPORT_RATIO_KTX/SRT(고속열차)  TRANSPORT_RATIO_관광버스  \\\n",
       "0            0.000000                       0.000000                   0.0   \n",
       "1            0.024229                       0.052863                   0.0   \n",
       "2            0.000000                       0.000000                   0.0   \n",
       "3            0.049080                       0.065831                   0.0   \n",
       "4            0.056604                       0.000000                   0.0   \n",
       "\n",
       "   TRANSPORT_RATIO_기타  TRANSPORT_RATIO_렌터카(승용/승합/버스 등등)  TRANSPORT_RATIO_배/선박  \\\n",
       "0            0.000000                          0.000000                   0.0   \n",
       "1            0.000000                          0.000000                   0.0   \n",
       "2            0.000000                          0.000000                   0.0   \n",
       "3            0.037618                          0.018809                   0.0   \n",
       "4            0.000000                          0.000000                   0.0   \n",
       "\n",
       "   TRANSPORT_RATIO_버스 + 지하철  TRANSPORT_RATIO_새마을/무궁화열차  \\\n",
       "0                  0.000000                   0.000000   \n",
       "1                  0.196035                   0.059471   \n",
       "2                  0.000000                   0.000000   \n",
       "3                  0.184953                   0.075235   \n",
       "4                  0.245283                   0.000000   \n",
       "\n",
       "   TRANSPORT_RATIO_시내/마을버스  TRANSPORT_RATIO_시외/고속버스  \\\n",
       "0                 0.000000                 0.000000   \n",
       "1                 0.077093                 0.088106   \n",
       "2                 0.000000                 0.000000   \n",
       "3                 0.015674                 0.028213   \n",
       "4                 0.000000                 0.207547   \n",
       "\n",
       "   TRANSPORT_RATIO_자가용(승용/승합/트럭 등등)  TRANSPORT_RATIO_자전거  TRANSPORT_RATIO_지하철  \\\n",
       "0                          1.000000             0.000000             0.000000   \n",
       "1                          0.251101             0.013216             0.143172   \n",
       "2                          1.000000             0.000000             0.000000   \n",
       "3                          0.379310             0.040752             0.021944   \n",
       "4                          0.000000             0.245283             0.056604   \n",
       "\n",
       "   TRANSPORT_RATIO_캠핑카(자차 및 렌탈)  TRANSPORT_RATIO_택시  TRANSPORT_RATIO_항공기  \n",
       "0                           0.0            0.000000                  0.0  \n",
       "1                           0.0            0.118943                  0.0  \n",
       "2                           0.0            0.000000                  0.0  \n",
       "3                           0.0            0.131661                  0.0  \n",
       "4                           0.0            0.245283                  0.0  "
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #### 3.3.9 통계 결과 확인 및 결측치 처리\n",
    "\n",
    "# %%\n",
    "# 결측치 0으로 대체\n",
    "place_stats.fillna(0, inplace=True)\n",
    "\n",
    "# 통계 결과 확인\n",
    "print(f\"계산된 관광지별 통계 수: {len(place_stats)}\")\n",
    "print(f\"통계 특성 수: {len(place_stats.columns) - 1}\")  # VISIT_AREA_NM 컬럼 제외\n",
    "place_stats.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 4. Test Set에 관광지별 통계 적용\n",
    "\n",
    "# %%\n",
    "# 4.1 기본 통계값 적용\n",
    "test_with_stats = df1.copy()\n",
    "\n",
    "# 기본 통계값 컬럼 추가\n",
    "for col in basic_stat_columns:\n",
    "    test_with_stats[f'{col}_mean'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 186295/186295 [1:03:31<00:00, 48.88it/s] \n"
     ]
    }
   ],
   "source": [
    "# 4.2 각 행에 해당 관광지의 통계값 적용\n",
    "for idx, row in tqdm(test_with_stats.iterrows(), total=len(test_with_stats)):\n",
    "    place = row['VISIT_AREA_NM']\n",
    "    place_subset = Train[Train['VISIT_AREA_NM'] == place]\n",
    "    \n",
    "    if len(place_subset) > 0:  # 해당 관광지가 Train set에 있는 경우\n",
    "        for col in basic_stat_columns:\n",
    "            test_with_stats.loc[idx, f'{col}_mean'] = place_subset[col].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### 4.3 확장된 특성 적용\n",
    "\n",
    "# %%\n",
    "# place_stats에서 필요한 열만 선택 (VISIT_AREA_NM과 통계 열만)\n",
    "stats_cols = [col for col in place_stats.columns if col != 'VISIT_AREA_NM']\n",
    "\n",
    "# test_with_stats와 place_stats 병합\n",
    "test_with_extended_stats = test_with_stats.merge(\n",
    "    place_stats, \n",
    "    on='VISIT_AREA_NM',\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "결측치가 있는 특성:\n",
      "GENDER_RATIO_남                  3229\n",
      "GENDER_RATIO_여                  3229\n",
      "AGE_RATIO_20                    3229\n",
      "AGE_RATIO_30                    3229\n",
      "AGE_RATIO_40                    3229\n",
      "                                ... \n",
      "TRANSPORT_RATIO_자전거             3229\n",
      "TRANSPORT_RATIO_지하철             3229\n",
      "TRANSPORT_RATIO_캠핑카(자차 및 렌탈)    3229\n",
      "TRANSPORT_RATIO_택시              3229\n",
      "TRANSPORT_RATIO_항공기             3229\n",
      "Length: 125, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 결측치 확인\n",
    "missing_stats = test_with_extended_stats[stats_cols].isna().sum()\n",
    "if missing_stats.sum() > 0:\n",
    "    print(\"결측치가 있는 특성:\")\n",
    "    print(missing_stats[missing_stats > 0])\n",
    "    # 결측치 0으로 대체\n",
    "    test_with_extended_stats.fillna(0, inplace=True)\n",
    "else:\n",
    "    print(\"모든 통계값이 성공적으로 적용되었습니다.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "확장된 특성을 포함한 데이터셋 저장 완료!\n"
     ]
    }
   ],
   "source": [
    "# ## 5. 최종 데이터셋 저장\n",
    "\n",
    "# %%\n",
    "# 데이터셋 저장\n",
    "new_train.to_csv('관광지_추천시스템_Trainset_확장.csv', index=False)\n",
    "test_with_extended_stats.to_csv('관광지_추천시스템_Testset_확장.csv', index=False)\n",
    "place_stats.to_csv('관광지_통계정보_확장.csv', index=False)\n",
    "\n",
    "print(\"확장된 특성을 포함한 데이터셋 저장 완료!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 Train set 크기: (618694, 36)\n",
      "최종 Test set 크기: (186295, 161)\n",
      "관광지별 통계 특성 수: 126\n"
     ]
    }
   ],
   "source": [
    "# ## 6. 데이터 검증 및 정리\n",
    "\n",
    "# %%\n",
    "# 결측치 제거 및 최종 크기 확인\n",
    "new_train.dropna(inplace=True)\n",
    "new_train.reset_index(drop=True, inplace=True)\n",
    "\n",
    "test_with_extended_stats.dropna(inplace=True)\n",
    "test_with_extended_stats.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(f\"최종 Train set 크기: {new_train.shape}\")\n",
    "print(f\"최종 Test set 크기: {test_with_extended_stats.shape}\")\n",
    "print(f\"관광지별 통계 특성 수: {len(place_stats.columns)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5회 이상 방문한 관광지 수: 7658\n",
      "필터링 전 Train set 크기: (618694, 36)\n",
      "필터링 후 Train set 크기: (614294, 36)\n",
      "제거된 행 수: 4400\n",
      "Train-Test Split 및 확장 특성 계산 완료!\n"
     ]
    }
   ],
   "source": [
    "# ## 7. 방문 빈도가 낮은 관광지 필터링 (5회 미만 방문)\n",
    "\n",
    "# %%\n",
    "# 방문 빈도 확인\n",
    "visit_counts = pd.DataFrame(new_train['VISIT_AREA_NM'].value_counts())\n",
    "visit_counts.columns = ['count']  # 열 이름 지정\n",
    "visit_counts['places'] = visit_counts.index\n",
    "\n",
    "five_or_more_places = list(visit_counts[visit_counts['count'] >= 5]['places'])\n",
    "print(f\"5회 이상 방문한 관광지 수: {len(five_or_more_places)}\")\n",
    "\n",
    "# 필터링 적용\n",
    "filtered_train = new_train.copy()\n",
    "filtered_indices = []\n",
    "for i in range(len(filtered_train)):\n",
    "    if filtered_train.loc[i, 'VISIT_AREA_NM'] not in five_or_more_places:\n",
    "        filtered_indices.append(i)\n",
    "        \n",
    "filtered_train = filtered_train.drop(filtered_indices, axis=0)\n",
    "filtered_train.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(f\"필터링 전 Train set 크기: {new_train.shape}\")\n",
    "print(f\"필터링 후 Train set 크기: {filtered_train.shape}\")\n",
    "print(f\"제거된 행 수: {len(new_train) - len(filtered_train)}\")\n",
    "\n",
    "# 필터링된 데이터셋 저장\n",
    "filtered_train.to_csv('관광지_추천시스템_Trainset_필터링_확장.csv', index=False)\n",
    "\n",
    "print(\"Train-Test Split 및 확장 특성 계산 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading preprocessed datasets...\n",
      "Train set shape: (614294, 36)\n",
      "Test set shape: (186295, 161)\n",
      "Place stats shape: (11467, 126)\n",
      "Preparing data for CatBoost model...\n",
      "Identifying and converting categorical features...\n",
      "Identified 24 categorical features:\n",
      "['MVMN_SE_NM', 'ACTIVITY_TYPE_CD', 'STORE_NM', 'REL_CD', 'VISIT_AREA_NM', 'SIDO', 'GUNGU', 'VISIT_AREA_TYPE_CD', 'TRAVEL_MISSION_PRIORITY', 'GENDER', 'AGE_GRP', 'INCOME', 'TRAVEL_STYL_1', 'TRAVEL_STYL_2', 'TRAVEL_STYL_3', 'TRAVEL_STYL_4', 'TRAVEL_STYL_5', 'TRAVEL_STYL_6', 'TRAVEL_STYL_7', 'TRAVEL_STYL_8', 'TRAVEL_MOTIVE_1', 'TRAVEL_NUM', 'TRAVEL_COMPANIONS_NUM', 'RESIDENCE_TIME_MIN_mean']\n",
      "Total features: 29\n",
      "Training CatBoost model...\n",
      "Training CatBoost model...\n",
      "Learning rate set to 0.100785\n",
      "0:\tlearn: 0.7577307\ttotal: 919ms\tremaining: 17m 35s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[186], line 74\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining CatBoost model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 74\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError during model training: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/travel_rec/lib/python3.8/site-packages/catboost/core.py:5873\u001b[0m, in \u001b[0;36mCatBoostRegressor.fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, graph, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   5871\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_function\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[1;32m   5872\u001b[0m     CatBoostRegressor\u001b[38;5;241m.\u001b[39m_check_is_compatible_loss(params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss_function\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m-> 5873\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcat_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5874\u001b[0m \u001b[43m                 \u001b[49m\u001b[43muse_best_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogging_level\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn_description\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5875\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric_period\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msilent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5876\u001b[0m \u001b[43m                 \u001b[49m\u001b[43msave_snapshot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msnapshot_interval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_cerr\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/travel_rec/lib/python3.8/site-packages/catboost/core.py:2410\u001b[0m, in \u001b[0;36mCatBoost._fit\u001b[0;34m(self, X, y, cat_features, text_features, embedding_features, pairs, graph, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[1;32m   2407\u001b[0m allow_clear_pool \u001b[38;5;241m=\u001b[39m train_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_clear_pool\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   2409\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m plot_wrapper(plot, plot_file, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining plots\u001b[39m\u001b[38;5;124m'\u001b[39m, [_get_train_dir(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_params())]):\n\u001b[0;32m-> 2410\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2411\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2412\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meval_sets\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2413\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2414\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2415\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minit_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m   2416\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2418\u001b[0m \u001b[38;5;66;03m# Have property feature_importance possibly set\u001b[39;00m\n\u001b[1;32m   2419\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_object\u001b[38;5;241m.\u001b[39m_get_loss_function_name()\n",
      "File \u001b[0;32m~/miniconda3/envs/travel_rec/lib/python3.8/site-packages/catboost/core.py:1790\u001b[0m, in \u001b[0;36m_CatBoostBase._train\u001b[0;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[1;32m   1789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_train\u001b[39m(\u001b[38;5;28mself\u001b[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001b[0;32m-> 1790\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_object\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_clear_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_object\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_trained_model_attributes()\n",
      "File \u001b[0;32m_catboost.pyx:5017\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_catboost.pyx:5066\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostRegressor\n",
    "import joblib\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # Suppress warning messages\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Load the processed datasets from the first code file\n",
    "print(\"Loading preprocessed datasets...\")\n",
    "filtered_train = pd.read_csv('관광지_추천시스템_Trainset_필터링_확장.csv')\n",
    "test_with_extended_stats = pd.read_csv('관광지_추천시스템_Testset_확장.csv')\n",
    "place_stats = pd.read_csv('관광지_통계정보_확장.csv')\n",
    "\n",
    "# Check the data\n",
    "print(f\"Train set shape: {filtered_train.shape}\")\n",
    "print(f\"Test set shape: {test_with_extended_stats.shape}\")\n",
    "print(f\"Place stats shape: {place_stats.shape}\")\n",
    "\n",
    "# Prepare data for CatBoost model\n",
    "# Remove columns that are not needed for prediction\n",
    "print(\"Preparing data for CatBoost model...\")\n",
    "train_cols_to_drop = ['TRAVEL_ID', 'TRAVELER_ID', 'REVISIT_INTENTION', \n",
    "                     'RCMDTN_INTENTION', 'RESIDENCE_TIME_MIN', 'REVISIT_YN']\n",
    "y_train = filtered_train['DGSTFN']\n",
    "X_train = filtered_train.drop(['DGSTFN'] + train_cols_to_drop, axis=1, errors='ignore')\n",
    "\n",
    "# Detect potential categorical columns and convert them to string type for CatBoost\n",
    "# This ensures CatBoost treats them properly rather than trying to convert to float\n",
    "categorical_features = []\n",
    "print(\"Identifying and converting categorical features...\")\n",
    "\n",
    "# Examine each column to determine categorical vs numerical\n",
    "for col in X_train.columns:\n",
    "    # Check first few values to determine if column might be categorical\n",
    "    sample_values = X_train[col].dropna().head(5)\n",
    "    is_categorical = False\n",
    "    \n",
    "    # If column name suggests it's categorical\n",
    "    if any(keyword in col.lower() for keyword in ['nm', 'cd', 'type', 'id', 'gender', 'age', 'sido', 'gungu', 'priority']):\n",
    "        is_categorical = True\n",
    "    # Or if values are non-numeric\n",
    "    elif any(isinstance(val, str) for val in sample_values):\n",
    "        is_categorical = True\n",
    "    # Or if number of unique values is small (likely categorical)\n",
    "    elif X_train[col].nunique() < 20:\n",
    "        is_categorical = True\n",
    "        \n",
    "    if is_categorical:\n",
    "        categorical_features.append(col)\n",
    "        # Convert to string to ensure proper handling\n",
    "        X_train[col] = X_train[col].astype(str)\n",
    "        \n",
    "print(f\"Identified {len(categorical_features)} categorical features:\")\n",
    "print(categorical_features)\n",
    "print(f\"Total features: {X_train.shape[1]}\")\n",
    "\n",
    "# Train CatBoost model with optimal hyperparameters from the second file\n",
    "print(\"Training CatBoost model...\")\n",
    "model = CatBoostRegressor(\n",
    "    n_estimators=1150,\n",
    "    max_depth=10,\n",
    "    subsample=0.95,\n",
    "    colsample_bylevel=0.95,\n",
    "    cat_features=categorical_features,\n",
    "    random_state=42,\n",
    "    verbose=100  # Show progress every 100 iterations\n",
    ")\n",
    "\n",
    "try:\n",
    "    print(\"Training CatBoost model...\")\n",
    "    model.fit(X_train, y_train)\n",
    "except Exception as e:\n",
    "    print(f\"Error during model training: {str(e)}\")\n",
    "    \n",
    "    # If training fails, let's try with more careful feature handling\n",
    "    print(\"Retrying with more careful feature handling...\")\n",
    "    \n",
    "    # Convert all columns to appropriate types\n",
    "    for col in X_train.columns:\n",
    "        if col in categorical_features:\n",
    "            X_train[col] = X_train[col].astype(str)\n",
    "        else:\n",
    "            # For numeric columns, ensure they're float type and handle missing values\n",
    "            try:\n",
    "                X_train[col] = pd.to_numeric(X_train[col], errors='coerce')\n",
    "                X_train[col] = X_train[col].fillna(X_train[col].mean())\n",
    "            except:\n",
    "                # If conversion fails, treat as categorical\n",
    "                print(f\"Converting {col} to categorical due to numeric conversion issue\")\n",
    "                categorical_features.append(col)\n",
    "                X_train[col] = X_train[col].astype(str)\n",
    "    \n",
    "    # Try again with updated features\n",
    "    model = CatBoostRegressor(\n",
    "        n_estimators=1150,\n",
    "        max_depth=10,\n",
    "        subsample=0.95,\n",
    "        colsample_bylevel=0.95,\n",
    "        cat_features=categorical_features,\n",
    "        random_state=42,\n",
    "        verbose=100\n",
    "    )\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "# Save the model\n",
    "print(\"Saving model...\")\n",
    "timestamp = time.strftime('%Y%m%d_%H%M%S')\n",
    "model_path = f'catboost_tourism_recommendation_model_{timestamp}.pkl'\n",
    "joblib.dump(model, model_path)\n",
    "print(f\"Model saved to {model_path}\")\n",
    "\n",
    "# Prepare test set data for recommendation generation\n",
    "print(\"Generating recommendations for test set...\")\n",
    "\n",
    "# Extract user information\n",
    "data = test_with_extended_stats[['TRAVEL_ID', 'SIDO', 'GUNGU', 'TRAVEL_MISSION_PRIORITY', \n",
    "                                'GENDER', 'AGE_GRP', 'INCOME',\n",
    "                                'TRAVEL_STYL_1', 'TRAVEL_STYL_2', 'TRAVEL_STYL_3', 'TRAVEL_STYL_4',\n",
    "                                'TRAVEL_STYL_5', 'TRAVEL_STYL_6', 'TRAVEL_STYL_7', 'TRAVEL_STYL_8',\n",
    "                                'TRAVEL_MOTIVE_1', 'TRAVEL_NUM', 'TRAVEL_COMPANIONS_NUM']]\n",
    "\n",
    "# Create a DataFrame with user information and the list of regions they've visited\n",
    "print(\"Processing user region information...\")\n",
    "data1 = pd.DataFrame(columns=['TRAVEL_ID', 'TRAVEL_MISSION_PRIORITY', 'GENDER', 'AGE_GRP', 'INCOME',\n",
    "                            'TRAVEL_STYL_1', 'TRAVEL_STYL_2', 'TRAVEL_STYL_3', 'TRAVEL_STYL_4',\n",
    "                            'TRAVEL_STYL_5', 'TRAVEL_STYL_6', 'TRAVEL_STYL_7', 'TRAVEL_STYL_8',\n",
    "                            'TRAVEL_MOTIVE_1', 'TRAVEL_NUM', 'TRAVEL_COMPANIONS_NUM', 'sido_gungu_list'])\n",
    "\n",
    "for i in tqdm(list(data['TRAVEL_ID'].unique())):\n",
    "    temp_df = data[data['TRAVEL_ID'] == i]\n",
    "    temp_df1 = temp_df[['SIDO', 'GUNGU']] # Check which regions each user has visited\n",
    "    temp_df1.reset_index(drop=True, inplace=True)\n",
    "    sido_gungu_visit = []\n",
    "    for j in range(len(temp_df1)):\n",
    "        sido_gungu_visit.append(temp_df1['SIDO'][j] + '+' + temp_df1['GUNGU'][j])\n",
    "    sido_gungu_list = list(set(sido_gungu_visit))\n",
    "    new = temp_df.drop(['SIDO', 'GUNGU'], axis=1) # Remove existing region columns\n",
    "    new = new.head(1)\n",
    "    new['sido_gungu_list'] = str(sido_gungu_list)\n",
    "    data1 = pd.concat([data1, new], axis=0) # Create new DataFrame\n",
    "\n",
    "data1.reset_index(drop=True, inplace=True)\n",
    "print(\"User region information processed.\")\n",
    "\n",
    "# Extract attraction information\n",
    "print(\"Processing attraction information...\")\n",
    "info = filtered_train[['SIDO', 'VISIT_AREA_NM', 'GUNGU', 'VISIT_AREA_TYPE_CD', \n",
    "                      'RESIDENCE_TIME_MIN_mean', 'RCMDTN_INTENTION_mean',\n",
    "                      'REVISIT_YN_mean', 'TRAVEL_COMPANIONS_NUM_mean', 'REVISIT_INTENTION_mean']]\n",
    "info.drop_duplicates(['VISIT_AREA_NM'], inplace=True)\n",
    "\n",
    "# Filter for attractions with minimum visits (5 or more) from train set\n",
    "print(\"Filtering attractions with 5 or more visits...\")\n",
    "visiting_list = filtered_train[['VISIT_AREA_NM']]\n",
    "visit_counts = pd.DataFrame(visiting_list.value_counts(), columns=['count'])\n",
    "visit_counts['VISIT_AREA_NM'] = visit_counts.index\n",
    "visit_counts.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Data preprocessing - clean up attraction names\n",
    "for i in range(len(visit_counts)):\n",
    "    visit_counts['VISIT_AREA_NM'][i] = str(visit_counts['VISIT_AREA_NM'][i])\n",
    "    visit_counts['VISIT_AREA_NM'][i] = visit_counts['VISIT_AREA_NM'][i].replace(\"(\",\"\").replace(\")\",\"\").replace(\",\",\"\").replace(\"\\''\",\"\")\n",
    "    visit_counts['VISIT_AREA_NM'][i] = visit_counts['VISIT_AREA_NM'][i][1:-1]\n",
    "\n",
    "# Keep only attractions with 5 or more visits\n",
    "visit_counts = visit_counts[visit_counts['count'] >= 5]\n",
    "visit_list = list(visit_counts['VISIT_AREA_NM'])\n",
    "print(f\"Number of attractions with 5 or more visits: {len(visit_list)}\")\n",
    "\n",
    "# Filter info DataFrame for attractions with 5 or more visits\n",
    "info.reset_index(drop=True, inplace=True)\n",
    "indices_to_drop = []\n",
    "for i in range(len(info)):\n",
    "    if info['VISIT_AREA_NM'][i] not in visit_list:\n",
    "        indices_to_drop.append(i)\n",
    "info = info.drop(indices_to_drop, axis=0)\n",
    "info.reset_index(drop=True, inplace=True)\n",
    "print(f\"Filtered attraction info shape: {info.shape}\")\n",
    "\n",
    "# Generate recommendations for each user\n",
    "print(\"Generating top 10 recommendations for each user...\")\n",
    "result = []\n",
    "for i in tqdm(range(len(data1))):\n",
    "    # Create an empty DataFrame for this user's predictions\n",
    "    final_df = pd.DataFrame(columns=['VISIT_AREA_NM', 'SIDO', 'GUNGU', 'VISIT_AREA_TYPE_CD',\n",
    "            'TRAVEL_MISSION_PRIORITY', 'GENDER', 'AGE_GRP', 'INCOME',\n",
    "            'TRAVEL_STYL_1', 'TRAVEL_STYL_2', 'TRAVEL_STYL_3', 'TRAVEL_STYL_4',\n",
    "            'TRAVEL_STYL_5', 'TRAVEL_STYL_6', 'TRAVEL_STYL_7', 'TRAVEL_STYL_8',\n",
    "            'TRAVEL_MOTIVE_1', 'TRAVEL_NUM', 'TRAVEL_COMPANIONS_NUM',\n",
    "            'RESIDENCE_TIME_MIN_mean', 'RCMDTN_INTENTION_mean', 'REVISIT_YN_mean',\n",
    "            'TRAVEL_COMPANIONS_NUM_mean', 'REVISIT_INTENTION_mean'])\n",
    "    \n",
    "    # Process the list of regions the user has visited\n",
    "    temp = data1['sido_gungu_list'][i].replace(\"[\",\"\").replace(\"]\",\"\").replace(\"\\'\",\"\").replace(\", \",\",\")\n",
    "    places_list = list(map(str, temp.split(\",\")))\n",
    "    \n",
    "    # For each region the user has visited\n",
    "    for q in places_list:\n",
    "        sido, gungu = map(str, q.split(\"+\"))\n",
    "        \n",
    "        # Find attractions in this region\n",
    "        info_df = info[(info['SIDO'] == sido) & (info['GUNGU'] == gungu)]\n",
    "        if info_df.empty:\n",
    "            continue\n",
    "            \n",
    "        info_df = info_df.copy()  # Create a copy to avoid SettingWithCopyWarning\n",
    "        info_df.drop(['SIDO'], inplace=True, axis=1)\n",
    "        info_df.reset_index(inplace=True, drop=True)\n",
    "        \n",
    "        # Get user information\n",
    "        data2 = data1.drop(['sido_gungu_list'], axis=1)\n",
    "        user_df = pd.DataFrame([data2.iloc[i].to_list()]*len(info_df), \n",
    "                              columns=['TRAVEL_ID', 'TRAVEL_MISSION_PRIORITY', 'GENDER', 'AGE_GRP', 'INCOME',\n",
    "                                    'TRAVEL_STYL_1', 'TRAVEL_STYL_2', 'TRAVEL_STYL_3', 'TRAVEL_STYL_4',\n",
    "                                    'TRAVEL_STYL_5', 'TRAVEL_STYL_6', 'TRAVEL_STYL_7', 'TRAVEL_STYL_8',\n",
    "                                    'TRAVEL_MOTIVE_1', 'TRAVEL_NUM', 'TRAVEL_COMPANIONS_NUM'])\n",
    "        \n",
    "        # Combine user and attraction info\n",
    "        df = pd.concat([user_df.reset_index(drop=True), info_df.reset_index(drop=True)], axis=1)\n",
    "        df = df[['VISIT_AREA_NM', 'SIDO', 'GUNGU', 'VISIT_AREA_TYPE_CD',\n",
    "               'TRAVEL_MISSION_PRIORITY', 'GENDER', 'AGE_GRP', 'INCOME',\n",
    "               'TRAVEL_STYL_1', 'TRAVEL_STYL_2', 'TRAVEL_STYL_3', 'TRAVEL_STYL_4',\n",
    "               'TRAVEL_STYL_5', 'TRAVEL_STYL_6', 'TRAVEL_STYL_7', 'TRAVEL_STYL_8',\n",
    "               'TRAVEL_MOTIVE_1', 'TRAVEL_NUM', 'TRAVEL_COMPANIONS_NUM',\n",
    "               'RESIDENCE_TIME_MIN_mean', 'RCMDTN_INTENTION_mean', 'REVISIT_YN_mean',\n",
    "               'TRAVEL_COMPANIONS_NUM_mean', 'REVISIT_INTENTION_mean']]\n",
    "        \n",
    "        # Convert all categorical features to string type for prediction\n",
    "        for col in categorical_features:\n",
    "            if col in df.columns:\n",
    "                df[col] = df[col].astype(str)\n",
    "        \n",
    "        # Add to the final DataFrame for this user\n",
    "        final_df = pd.concat([final_df, df], axis=0)\n",
    "    \n",
    "    # Reset index and remove duplicates\n",
    "    if final_df.empty:\n",
    "        # If no attractions were found for this user's regions, add empty result\n",
    "        rec = []\n",
    "        result.append(rec)\n",
    "        continue\n",
    "    \n",
    "    final_df.reset_index(drop=True, inplace=True)\n",
    "    final_df.drop_duplicates(['VISIT_AREA_NM'], inplace=True)\n",
    "    \n",
    "    # Remove TRAVEL_ID for prediction (not used in the model)\n",
    "    pred_df = final_df.drop(['TRAVEL_ID'], axis=1, errors='ignore')\n",
    "    \n",
    "    # Prepare prediction data - make sure it has the same format as training data\n",
    "    for col in categorical_features:\n",
    "        if col in pred_df.columns:\n",
    "            pred_df[col] = pred_df[col].astype(str)\n",
    "    \n",
    "    # Ensure all columns needed for prediction are present\n",
    "    for col in X_train.columns:\n",
    "        if col not in pred_df.columns:\n",
    "            # If a column is missing, create it with default values\n",
    "            if col in categorical_features:\n",
    "                pred_df[col] = \"unknown\"\n",
    "            else:\n",
    "                pred_df[col] = 0\n",
    "    \n",
    "    # Keep only columns used during training and in the same order\n",
    "    pred_df = pred_df[X_train.columns]\n",
    "    \n",
    "    try:\n",
    "        # Model prediction\n",
    "        y_pred = model.predict(pred_df)\n",
    "    except Exception as e:\n",
    "        print(f\"Error during prediction for user {i}: {str(e)}\")\n",
    "        # Create empty predictions if there's an error\n",
    "        y_pred = np.zeros(len(pred_df))\n",
    "    y_pred = pd.DataFrame(y_pred, columns=['y_pred'])\n",
    "    test_df1 = pd.concat([final_df, y_pred], axis=1)\n",
    "    test_df1.sort_values(by=['y_pred'], axis=0, ascending=False, inplace=True)  # Sort by prediction score\n",
    "    \n",
    "    # Select top 10 attractions\n",
    "    test_df1 = test_df1.iloc[0:10,]\n",
    "    \n",
    "    # Get list of recommended attractions\n",
    "    visiting_candidates = list(test_df1['VISIT_AREA_NM'])\n",
    "    \n",
    "    # Create result record with user info and recommendations\n",
    "    test_df2 = test_df1[['SIDO', 'TRAVEL_MISSION_PRIORITY', 'GENDER', 'AGE_GRP', 'INCOME',\n",
    "                        'TRAVEL_STYL_1', 'TRAVEL_STYL_2', 'TRAVEL_STYL_3', 'TRAVEL_STYL_4',\n",
    "                        'TRAVEL_STYL_5', 'TRAVEL_STYL_6', 'TRAVEL_STYL_7', 'TRAVEL_STYL_8',\n",
    "                        'TRAVEL_MOTIVE_1', 'TRAVEL_NUM', 'TRAVEL_COMPANIONS_NUM']]\n",
    "    \n",
    "    if len(test_df2) == 0:\n",
    "        rec = []\n",
    "        result.append(rec)\n",
    "    else:\n",
    "        rec = test_df2.iloc[0].to_list()\n",
    "        rec.append(visiting_candidates)\n",
    "        result.append(rec)\n",
    "\n",
    "# Create results DataFrame with recommendations\n",
    "final_df = pd.DataFrame(result,\n",
    "                      columns=['SIDO', 'TRAVEL_MISSION_PRIORITY', 'GENDER', 'AGE_GRP', 'INCOME',\n",
    "                               'TRAVEL_STYL_1', 'TRAVEL_STYL_2', 'TRAVEL_STYL_3', 'TRAVEL_STYL_4',\n",
    "                               'TRAVEL_STYL_5', 'TRAVEL_STYL_6', 'TRAVEL_STYL_7', 'TRAVEL_STYL_8',\n",
    "                               'TRAVEL_MOTIVE_1', 'TRAVEL_NUM', 'TRAVEL_COMPANIONS_NUM', \n",
    "                               'recommend_result_place'])\n",
    "\n",
    "# Keep only recommendations column and add TRAVEL_ID\n",
    "final_df = final_df[['recommend_result_place']]\n",
    "travel_id = data1[['TRAVEL_ID']]\n",
    "travel_id.reset_index(drop=True, inplace=True)\n",
    "final_df = pd.concat([travel_id, final_df], axis=1)\n",
    "\n",
    "# Save recommendations\n",
    "output_path = f'catboost_recommendations_{timestamp}.csv'\n",
    "final_df.to_csv(output_path, index=False)\n",
    "print(f\"Recommendations saved to {output_path}\")\n",
    "\n",
    "# Calculate Recall@10\n",
    "print(\"Calculating Recall@10 for recommendations...\")\n",
    "\n",
    "# Identify users with fewer than 10 recommendations\n",
    "travel_id_list = []\n",
    "for i in range(len(final_df)):\n",
    "    recommend_list = final_df['recommend_result_place'][i]\n",
    "    if pd.isna(recommend_list):\n",
    "        travel_id_list.append(final_df['TRAVEL_ID'][i])\n",
    "        continue\n",
    "    if str(recommend_list).count(',') < 9:\n",
    "        travel_id_list.append(final_df['TRAVEL_ID'][i])\n",
    "\n",
    "# Extract list of region names (without -구, -시, -군 suffixes)\n",
    "places = list(set(test_with_extended_stats['GUNGU']))\n",
    "for i in range(len(places)):\n",
    "    if places[i][-1] == '구' or places[i][-1] == '시' or places[i][-1] == '군':\n",
    "        places[i] = places[i][:-1]\n",
    "\n",
    "# Calculate Recall@10 for each user\n",
    "recall_10_list = []\n",
    "for i in tqdm(list(test_with_extended_stats['TRAVEL_ID'].unique())):\n",
    "    # If user has fewer than 10 recommendations, set recall to 0\n",
    "    if i in travel_id_list:\n",
    "        recall_10_list.append(0)\n",
    "        continue\n",
    "    \n",
    "    # Get attractions this user was satisfied with (rating >= 4)\n",
    "    satisfied = test_with_extended_stats[test_with_extended_stats['TRAVEL_ID'] == i]\n",
    "    satisfied.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    satisfied1 = satisfied[satisfied['DGSTFN'] >= 4]\n",
    "    if len(satisfied1) == 0:  # If user wasn't satisfied with any attractions\n",
    "        recall_10_list.append(0)\n",
    "        continue\n",
    "    \n",
    "    item_list = list(set(satisfied1['VISIT_AREA_NM']))\n",
    "    \n",
    "    # Get the model's recommendations for this user\n",
    "    recommend_list = final_df[final_df['TRAVEL_ID'] == i]['recommend_result_place']\n",
    "    \n",
    "    # Count matches between satisfied attractions and recommendations\n",
    "    summ = 0\n",
    "    for n in item_list:\n",
    "        word_list = list(n.split(' '))\n",
    "        if word_list[-1][-1] == '점':  # Remove location suffix (e.g., \"강남점\")\n",
    "            del word_list[-1]\n",
    "        for o in word_list:\n",
    "            if o in places:  # Skip region names\n",
    "                pass\n",
    "            else:\n",
    "                for p in recommend_list:  # Check if word is in recommended place name\n",
    "                    if o in str(p):\n",
    "                        summ += 1\n",
    "    \n",
    "    # Calculate recall@10\n",
    "    recall10_for_1user = summ / min(10, len(satisfied1))\n",
    "    if recall10_for_1user > 1:\n",
    "        recall10_for_1user = 1\n",
    "    recall_10_list.append(recall10_for_1user)\n",
    "\n",
    "# Calculate and display overall Recall@10\n",
    "recall_10 = np.mean(recall_10_list)\n",
    "print(f\"Recall@10: {recall_10:.4f}\")\n",
    "\n",
    "# Save Recall@10 results\n",
    "recall_df = pd.DataFrame({\n",
    "    'TRAVEL_ID': list(test_with_extended_stats['TRAVEL_ID'].unique()),\n",
    "    'Recall@10': recall_10_list\n",
    "})\n",
    "recall_df.to_csv(f'recall_at_10_results_{timestamp}.csv', index=False)\n",
    "print(f\"Recall@10 results saved to recall_at_10_results_{timestamp}.csv\")\n",
    "\n",
    "print(\"CatBoost recommendation process completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "travel_rec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
